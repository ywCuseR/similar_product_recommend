{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c0ba3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#讀取資料集：如果資料集過大，可以先分割；小資料集則可以一次性讀取\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "class DataLoader:\n",
    "    def __init__(self):\n",
    "        self.dataframes = {}\n",
    "\n",
    "    def load_csv(self, name, filepath):\n",
    "        \"\"\"讀取 CSV 並以指定名稱儲存\"\"\"\n",
    "        try:\n",
    "            df = pd.read_csv(filepath)\n",
    "            self.dataframes[name] = df\n",
    "            print(f\"{name} 資料已載入，共 {len(df)} 筆資料。\")\n",
    "        except Exception as e:\n",
    "            print(f\"載入 {filepath} 時發生錯誤：{e}\")\n",
    "\n",
    "    def preview(self, name, n=2):\n",
    "        \"\"\"顯示指定資料的前 n 筆與後 n 筆\"\"\"\n",
    "        if name in self.dataframes:\n",
    "            df = self.dataframes[name]\n",
    "            print(f\"=== {name} 頭 {n} 筆資料 ===\")\n",
    "            print(df.head(n))\n",
    "            print(f\"=== {name} 後 {n} 筆資料 ===\")\n",
    "            print(df.tail(n))\n",
    "        else:\n",
    "            print(f\"{name} 尚未載入，請先使用 load_csv()。\")\n",
    "\n",
    "    def get_dataframe(self, name):\n",
    "        \"\"\"取得已載入的 DataFrame\"\"\"\n",
    "        return self.dataframes.get(name, None)\n",
    "\n",
    "    def split_csv(self, input_file, output_folder, parts=20, encoding='utf-8'):\n",
    "        \"\"\"將大型 CSV 分割為多份\"\"\"\n",
    "        if not os.path.exists(output_folder):\n",
    "            os.makedirs(output_folder)\n",
    "\n",
    "        # 計算總筆數（不含標題列）\n",
    "        try:\n",
    "            total_rows = sum(1 for _ in open(input_file, encoding=encoding)) - 1\n",
    "            chunk_size = total_rows // parts + 1\n",
    "            print(f\"總筆數: {total_rows}, 每份約 {chunk_size} 筆\")\n",
    "\n",
    "            chunk_number = 0\n",
    "            for chunk in pd.read_csv(input_file, chunksize=chunk_size, encoding=encoding, low_memory=False):\n",
    "                output_path = os.path.join(output_folder, f\"chunk_{chunk_number + 1}.csv\")\n",
    "                chunk.to_csv(output_path, index=False, encoding=encoding)\n",
    "                chunk_number += 1\n",
    "                print(f\"已分割第 {chunk_number} 份：{output_path}\")\n",
    "\n",
    "            print(\"分割完成\")\n",
    "        except Exception as e:\n",
    "            print(f\"分割 {input_file} 時發生錯誤：{e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83195a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#合併資料，只取ShopMemberId, SalePageId, SalePageTitle三個欄位\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "\n",
    "def batch_generate_order_summaries(\n",
    "    ordersplit_dir, \n",
    "    salepage_csv_path, \n",
    "    output_dir\n",
    "):\n",
    "    # 讀取 SalePage.csv\n",
    "    try:\n",
    "        salepage_df = pd.read_csv(salepage_csv_path, dtype=str)\n",
    "    except Exception as e:\n",
    "        print(f\"讀取 {salepage_csv_path} 時發生錯誤：{e}\")\n",
    "        return\n",
    "\n",
    "    if 'SalePageId' not in salepage_df.columns or 'SalePageTitle' not in salepage_df.columns:\n",
    "        print(\"SalePage 資料缺少必要欄位\")\n",
    "        return\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # 收集 chunk 檔案，排除 chunk_1.csv 和 chunk_20.csv\n",
    "    chunk_files = sorted(glob.glob(os.path.join(ordersplit_dir, \"chunk_*.csv\")))\n",
    "    chunk_files = [\n",
    "        f for f in chunk_files \n",
    "        if not (f.endswith(\"chunk_1.csv\") or f.endswith(\"chunk_20.csv\"))\n",
    "    ]\n",
    "\n",
    "    if not chunk_files:\n",
    "        print(\"找不到有效的 chunk_*.csv 檔案\")\n",
    "        return\n",
    "\n",
    "    for chunk_file in chunk_files:\n",
    "        filename = os.path.basename(chunk_file)\n",
    "        output_path = os.path.join(output_dir, f\"output_{filename}\")\n",
    "\n",
    "        try:\n",
    "            order_df = pd.read_csv(chunk_file, dtype=str)\n",
    "        except Exception as e:\n",
    "            print(f\"讀取 {filename} 發生錯誤：{e}\")\n",
    "            continue\n",
    "\n",
    "        if 'ShopMemberId' not in order_df.columns or 'SalePageId' not in order_df.columns:\n",
    "            print(f\"{filename} 缺少必要欄位，跳過\")\n",
    "            continue\n",
    "\n",
    "        merged = order_df[['ShopMemberId', 'SalePageId']].copy()\n",
    "        merged = merged.merge(\n",
    "            salepage_df[['SalePageId', 'SalePageTitle']], \n",
    "            on='SalePageId', \n",
    "            how='left'\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            merged.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "            print(f\"已輸出：{output_path} ({len(merged)} 筆)\")\n",
    "        except Exception as e:\n",
    "            print(f\"儲存 {output_path} 時錯誤：{e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7073cb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#篩選資料：刪除'退貨'的資料、留下 SalePageId 有值的資料、補上SalePageTitle的值、排除不需要的資料\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "\n",
    "def filter_return_status(df):\n",
    "    \"\"\"過濾掉 StatusDef 為 'Return' 的資料\"\"\"\n",
    "    if 'StatusDef' in df.columns:\n",
    "        return df[df['StatusDef'] != 'Return'].copy()\n",
    "    return df\n",
    "\n",
    "def batch_generate_order_summaries(\n",
    "    ordersplit_dir, \n",
    "    salepage_csv_path, \n",
    "    output_dir\n",
    "):\n",
    "    # 讀取 SalePage.csv\n",
    "    try:\n",
    "        salepage_df = pd.read_csv(salepage_csv_path, dtype=str)\n",
    "    except Exception as e:\n",
    "        print(f\"讀取 {salepage_csv_path} 時發生錯誤：{e}\")\n",
    "        return\n",
    "\n",
    "    if 'SalePageId' not in salepage_df.columns or 'SalePageTitle' not in salepage_df.columns:\n",
    "        print(\"SalePage 資料缺少必要欄位\")\n",
    "        return\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # 收集所有 chunk_*.csv 檔案（不再排除 chunk_1.csv 和 chunk_20.csv）\n",
    "    chunk_files = sorted(glob.glob(os.path.join(ordersplit_dir, \"chunk_*.csv\")))\n",
    "\n",
    "    if not chunk_files:\n",
    "        print(\"找不到有效的 chunk_*.csv 檔案\")\n",
    "        return\n",
    "\n",
    "    for chunk_file in chunk_files:\n",
    "        filename = os.path.basename(chunk_file)\n",
    "        output_path = os.path.join(output_dir, f\"output_{filename}\")\n",
    "\n",
    "        try:\n",
    "            order_df = pd.read_csv(chunk_file, dtype=str)\n",
    "        except Exception as e:\n",
    "            print(f\"讀取 {filename} 發生錯誤：{e}\")\n",
    "            continue\n",
    "\n",
    "        # 過濾 StatusDef = 'Return'\n",
    "        order_df = filter_return_status(order_df)\n",
    "\n",
    "        if 'ShopMemberId' not in order_df.columns or 'SalePageId' not in order_df.columns:\n",
    "            print(f\"{filename} 缺少必要欄位，跳過\")\n",
    "            continue\n",
    "\n",
    "        merged = order_df[['ShopMemberId', 'SalePageId']].copy()\n",
    "        merged = merged.merge(\n",
    "            salepage_df[['SalePageId', 'SalePageTitle']], \n",
    "            on='SalePageId', \n",
    "            how='left'\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            merged.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "            print(f\"已輸出：{output_path} ({len(merged)} 筆)\")\n",
    "        except Exception as e:\n",
    "            print(f\"儲存 {output_path} 時錯誤：{e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161277fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#統計分析\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "class DataAnalyzer:\n",
    "    def __init__(self, filepath):\n",
    "        \"\"\"初始化並載入資料\"\"\"\n",
    "        try:\n",
    "            self.filepath = filepath\n",
    "            self.df = pd.read_csv(filepath, dtype=str)\n",
    "            self.total_rows = len(self.df)\n",
    "            print(f\"資料已載入：{filepath}\")\n",
    "            print(f\"資料筆數: {self.total_rows}\")\n",
    "            print(f\"欄位名稱: {self.df.columns.tolist()}\")\n",
    "        except Exception as e:\n",
    "            print(f\"讀取資料時發生錯誤：{e}\")\n",
    "            self.df = None\n",
    "            self.total_rows = 0\n",
    "\n",
    "    def describe(self):\n",
    "        \"\"\"輸出基本統計描述\"\"\"\n",
    "        if self.df is not None:\n",
    "            print(\"\\n基本統計描述：\")\n",
    "            print(self.df.describe(include='all'))\n",
    "        else:\n",
    "            print(\"尚未載入資料，無法執行描述統計。\")\n",
    "\n",
    "    def show_top10_cumulative(self, column_name):\n",
    "        \"\"\"顯示欄位值前10名的出現次數與累積百分比\"\"\"\n",
    "        if self.df is not None:\n",
    "            if column_name in self.df.columns:\n",
    "                counts = self.df[column_name].value_counts(dropna=False)\n",
    "                top10 = counts.head(10)\n",
    "                percent = top10 / self.total_rows * 100\n",
    "                cum_percent = percent.cumsum().round(4)\n",
    "                summary = pd.DataFrame({\n",
    "                    'count': top10,\n",
    "                    'cumulative_percentage (%)': cum_percent\n",
    "                })\n",
    "                print(f\"\\n{column_name} Top 10 出現頻率與累積百分比：\")\n",
    "                print(summary)\n",
    "            else:\n",
    "                print(f\"欄位 '{column_name}' 不存在。\")\n",
    "        else:\n",
    "            print(\"尚未載入資料，無法顯示統計。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25cc5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#分群、降維、可視化\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def load_and_preprocess_data(filepath, top_n_items=20):\n",
    "    \"\"\"讀取資料並建立 0/1 會員-商品矩陣\"\"\"\n",
    "    df = pd.read_csv(filepath)\n",
    "    top_items = df['SalePageId'].value_counts().head(top_n_items).index\n",
    "    df_filtered = df[df['SalePageId'].isin(top_items)]\n",
    "    user_item = pd.crosstab(df_filtered['ShopMemberId'], df_filtered['SalePageId']).clip(upper=1)\n",
    "    return user_item\n",
    "\n",
    "def cluster_users(user_item, n_clusters=10, pca_components=2, cluster_on_pca=True):\n",
    "    \"\"\"執行標準化、降維（PCA）和分群\"\"\"\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(user_item)\n",
    "\n",
    "    if cluster_on_pca:\n",
    "        pca = PCA(n_components=pca_components)\n",
    "        X_pca = pca.fit_transform(X_scaled)\n",
    "        kmeans = MiniBatchKMeans(n_clusters=n_clusters, random_state=42, batch_size=10000)\n",
    "        clusters = kmeans.fit_predict(X_pca)\n",
    "        user_item['Cluster'] = clusters\n",
    "        return user_item, X_pca, clusters\n",
    "    else:\n",
    "        kmeans = MiniBatchKMeans(n_clusters=n_clusters, random_state=42, batch_size=10000)\n",
    "        clusters = kmeans.fit_predict(X_scaled)\n",
    "        user_item['Cluster'] = clusters\n",
    "        return user_item, X_scaled, clusters\n",
    "\n",
    "def plot_clusters(X_2d, clusters, title='K-Means Cluster Result (After PCA)'):\n",
    "    \"\"\"繪製 2D 散佈圖\"\"\"\n",
    "    plot_df = pd.DataFrame(X_2d, columns=['PCA1', 'PCA2'])\n",
    "    plot_df['Cluster'] = clusters\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.scatterplot(data=plot_df, x='PCA1', y='PCA2', hue='Cluster', palette='tab10')\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"PCA Component 1\")\n",
    "    plt.ylabel(\"PCA Component 2\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3cc252",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    \n",
    "#     loader = DataLoader()\n",
    "    \n",
    "#     #一次性讀取資料集\n",
    "#     loader.load_csv(\"salepage\", \"C:/Users/user/Desktop/91APPDataset/SalePage.csv\")\n",
    "#     loader.preview(\"salepage\")\n",
    "#     salepage_df = loader.get_dataframe(\"salepage\")\n",
    "    \n",
    "#     loader.load_csv(\"order2\", \"C:/Users/user/Desktop/Ordersplit/chunk_2.csv\")\n",
    "#     loader.preview(\"order2\")\n",
    "#     salepage_df = loader.get_dataframe(\"order1\")\n",
    "    \n",
    "#     #分割大型資料\n",
    "#     loader.split_csv(\"C:/Users/user/Desktop/91APPDataset/Order_TS.csv\", \n",
    "#                      \"C:/Users/user/Desktop/Ordersplit\", \n",
    "#                      parts=20, encoding=\"utf-8\"\n",
    "#     )\n",
    "\n",
    "#     #合併資料、同時刪除退貨資料\n",
    "#     batch_generate_order_summaries(\n",
    "#         ordersplit_dir=\"C:/Users/user/Desktop/Ordersplit\",\n",
    "#         salepage_csv_path=\"C:/Users/user/Desktop/91APPDataset/SalePage.csv\",\n",
    "#         output_dir=\"C:/Users/user/Desktop/Ordersplit_Output\"\n",
    "#     )\n",
    "    \n",
    "    \n",
    "#     #篩遠資料\n",
    "#     # 1. 篩選有效的 SalePageId 的資料\n",
    "#     f = DataFilter()\n",
    "#     f.merge_valid_salepage_rows(\n",
    "#         input_dir=r\"C:/Users/user/Desktop/Ordersplit_Output\",\n",
    "#         output_path=r\"C:/Users/user/Desktop/Ordersplit_Output2/merged_salepage_valid.csv\"\n",
    "#     )\n",
    "#     # 2. 補上 SalePageTitle\n",
    "#     f.fill_salepage_title(\n",
    "#         salepage_csv_path=r\"C:/Users/user/Desktop/91APPDataset/SalePage.csv\",\n",
    "#         output_path=r\"C:/Users/user/Desktop/Ordersplit_Output2/filled_salepage_data.csv\"\n",
    "#     )\n",
    "#     #出現多次的商品是：id=7855864 (贈)vivo數位印花、id=8995530 (贈)印花貼紙  \n",
    "#     # 3. 排除特定 SalePageId\n",
    "#     f.exclude_salepage_ids(\n",
    "#         exclude_ids=['7855864', '8995530'],\n",
    "#         output_path=r\"C:/Users/user/Desktop/Ordersplit_Output2/filtered_salepage_data.csv\"\n",
    "#     )\n",
    "    \n",
    "    \n",
    "    #資料集的統計資料\n",
    "    analyzer = DataAnalyzer(r\"C:/Users/user/Desktop/Ordersplit_Output2/filtered_salepage_data.csv\")\n",
    "    analyzer.describe()\n",
    "    analyzer.show_top10_cumulative(\"SalePageId\")\n",
    "    \n",
    "\n",
    "    # 選出前20筆商品來分群、分群與降維、繪圖、顯示每群的購買偏好\n",
    "    file_path = 'C:/Users/user/Desktop/Ordersplit_Output/filtered_salepage_data.csv'\n",
    "    user_item = load_and_preprocess_data(file_path, top_n_items=20)\n",
    "    user_item, X_pca, clusters = cluster_users(user_item, n_clusters=10, pca_components=2, cluster_on_pca=True)\n",
    "    plot_clusters(X_pca, clusters)\n",
    "    cluster_profiles = user_item.groupby('Cluster').mean()\n",
    "    print(cluster_profiles)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64b18f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
